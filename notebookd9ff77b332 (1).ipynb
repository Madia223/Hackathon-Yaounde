{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-23T13:23:22.636902Z",
     "iopub.status.busy": "2024-12-23T13:23:22.636606Z",
     "iopub.status.idle": "2024-12-23T13:23:48.246461Z",
     "shell.execute_reply": "2024-12-23T13:23:48.245482Z",
     "shell.execute_reply.started": "2024-12-23T13:23:22.636871Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\user\\lib\\site-packages (24.3.1)\n",
      "Collecting transformers==4.47.1\n",
      "  Downloading transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting jiwer\n",
      "  Downloading jiwer-3.0.5-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: soundfile in c:\\users\\user\\lib\\site-packages (0.12.1)\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting bnunicodenormalizer\n",
      "  Downloading bnunicodenormalizer-0.1.7-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\lib\\site-packages (from transformers==4.47.1) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\user\\lib\\site-packages (from transformers==4.47.1) (0.25.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\lib\\site-packages (from transformers==4.47.1) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\lib\\site-packages (from transformers==4.47.1) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\lib\\site-packages (from transformers==4.47.1) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\lib\\site-packages (from transformers==4.47.1) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\lib\\site-packages (from transformers==4.47.1) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers==4.47.1)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\user\\lib\\site-packages (from transformers==4.47.1) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\lib\\site-packages (from transformers==4.47.1) (4.66.5)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.3 in c:\\users\\user\\lib\\site-packages (from jiwer) (8.1.7)\n",
      "Collecting rapidfuzz<4,>=3 (from jiwer)\n",
      "  Downloading rapidfuzz-3.11.0-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\user\\lib\\site-packages (from soundfile) (1.16.0)\n",
      "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\user\\lib\\site-packages (from evaluate) (3.2.0)\n",
      "Requirement already satisfied: dill in c:\\users\\user\\lib\\site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\lib\\site-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: xxhash in c:\\users\\user\\lib\\site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\user\\lib\\site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in c:\\users\\user\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\user\\lib\\site-packages (from cffi>=1.0->soundfile) (2.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\lib\\site-packages (from click<9.0.0,>=8.1.3->jiwer) (0.4.6)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\user\\lib\\site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\user\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.11.11)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.47.1) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\lib\\site-packages (from requests->transformers==4.47.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\lib\\site-packages (from requests->transformers==4.47.1) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\lib\\site-packages (from requests->transformers==4.47.1) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\lib\\site-packages (from requests->transformers==4.47.1) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\lib\\site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\lib\\site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\lib\\site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\user\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\user\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\user\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\user\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Downloading transformers-4.47.1-py3-none-any.whl (10.1 MB)\n",
      "   ---------------------------------------- 0.0/10.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/10.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/10.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/10.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/10.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/10.1 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/10.1 MB 258.0 kB/s eta 0:00:38\n",
      "   -- ------------------------------------- 0.5/10.1 MB 258.0 kB/s eta 0:00:38\n",
      "   -- ------------------------------------- 0.5/10.1 MB 258.0 kB/s eta 0:00:38\n",
      "   -- ------------------------------------- 0.5/10.1 MB 258.0 kB/s eta 0:00:38\n",
      "   --- ------------------------------------ 0.8/10.1 MB 282.0 kB/s eta 0:00:34\n",
      "   --- ------------------------------------ 0.8/10.1 MB 282.0 kB/s eta 0:00:34\n",
      "   --- ------------------------------------ 0.8/10.1 MB 282.0 kB/s eta 0:00:34\n",
      "   --- ------------------------------------ 0.8/10.1 MB 282.0 kB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 1.0/10.1 MB 275.1 kB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 1.0/10.1 MB 275.1 kB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 1.0/10.1 MB 275.1 kB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 1.0/10.1 MB 275.1 kB/s eta 0:00:34\n",
      "   ----- ---------------------------------- 1.3/10.1 MB 278.4 kB/s eta 0:00:32\n",
      "   ----- ---------------------------------- 1.3/10.1 MB 278.4 kB/s eta 0:00:32\n",
      "   ----- ---------------------------------- 1.3/10.1 MB 278.4 kB/s eta 0:00:32\n",
      "   ----- ---------------------------------- 1.3/10.1 MB 278.4 kB/s eta 0:00:32\n",
      "   ------ --------------------------------- 1.6/10.1 MB 291.3 kB/s eta 0:00:30\n",
      "   ------ --------------------------------- 1.6/10.1 MB 291.3 kB/s eta 0:00:30\n",
      "   ------ --------------------------------- 1.6/10.1 MB 291.3 kB/s eta 0:00:30\n",
      "   ------- -------------------------------- 1.8/10.1 MB 305.9 kB/s eta 0:00:28\n",
      "   ------- -------------------------------- 1.8/10.1 MB 305.9 kB/s eta 0:00:28\n",
      "   -------- ------------------------------- 2.1/10.1 MB 329.0 kB/s eta 0:00:25\n",
      "   -------- ------------------------------- 2.1/10.1 MB 329.0 kB/s eta 0:00:25\n",
      "   --------- ------------------------------ 2.4/10.1 MB 347.7 kB/s eta 0:00:23\n",
      "   --------- ------------------------------ 2.4/10.1 MB 347.7 kB/s eta 0:00:23\n",
      "   ---------- ----------------------------- 2.6/10.1 MB 362.1 kB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 2.9/10.1 MB 394.7 kB/s eta 0:00:19\n",
      "   ----------- ---------------------------- 2.9/10.1 MB 394.7 kB/s eta 0:00:19\n",
      "   ------------ --------------------------- 3.1/10.1 MB 409.2 kB/s eta 0:00:18\n",
      "   ------------- -------------------------- 3.4/10.1 MB 424.8 kB/s eta 0:00:16\n",
      "   ------------- -------------------------- 3.4/10.1 MB 424.8 kB/s eta 0:00:16\n",
      "   --------------- ------------------------ 3.9/10.1 MB 468.8 kB/s eta 0:00:14\n",
      "   --------------- ------------------------ 3.9/10.1 MB 468.8 kB/s eta 0:00:14\n",
      "   ----------------- ---------------------- 4.5/10.1 MB 510.3 kB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 4.5/10.1 MB 510.3 kB/s eta 0:00:12\n",
      "   ------------------ --------------------- 4.7/10.1 MB 516.7 kB/s eta 0:00:11\n",
      "   -------------------- ------------------- 5.2/10.1 MB 560.2 kB/s eta 0:00:09\n",
      "   --------------------- ------------------ 5.5/10.1 MB 578.5 kB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 5.8/10.1 MB 595.1 kB/s eta 0:00:08\n",
      "   ------------------------ --------------- 6.3/10.1 MB 631.5 kB/s eta 0:00:07\n",
      "   -------------------------- ------------- 6.8/10.1 MB 673.3 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 6.8/10.1 MB 673.3 kB/s eta 0:00:05\n",
      "   ------------------------------ --------- 7.6/10.1 MB 720.5 kB/s eta 0:00:04\n",
      "   ------------------------------ --------- 7.6/10.1 MB 720.5 kB/s eta 0:00:04\n",
      "   --------------------------------- ------ 8.4/10.1 MB 764.8 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 8.7/10.1 MB 780.3 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 9.2/10.1 MB 810.3 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 9.7/10.1 MB 840.1 kB/s eta 0:00:01\n",
      "   ---------------------------------------  10.0/10.1 MB 852.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.1/10.1 MB 858.4 kB/s eta 0:00:00\n",
      "Downloading jiwer-3.0.5-py3-none-any.whl (21 kB)\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "Downloading bnunicodenormalizer-0.1.7-py3-none-any.whl (23 kB)\n",
      "Downloading rapidfuzz-3.11.0-cp312-cp312-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.6 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 0.8/1.6 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.6/1.6 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 2.3 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.4 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 1.0/2.4 MB 3.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.6/2.4 MB 3.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.1/2.4 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 2.8 MB/s eta 0:00:00\n",
      "Installing collected packages: bnunicodenormalizer, rapidfuzz, jiwer, tokenizers, transformers, evaluate\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.20.1\n",
      "    Uninstalling tokenizers-0.20.1:\n",
      "      Successfully uninstalled tokenizers-0.20.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.45.2\n",
      "    Uninstalling transformers-4.45.2:\n",
      "      Successfully uninstalled transformers-4.45.2\n",
      "Successfully installed bnunicodenormalizer-0.1.7 evaluate-0.4.3 jiwer-3.0.5 rapidfuzz-3.11.0 tokenizers-0.21.0 transformers-4.47.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'apt' n'est pas reconnu en tant que commande interne\n",
      "ou externe, un programme ex�cutable ou un fichier de commandes.\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install transformers==4.47.1 jiwer soundfile evaluate bnunicodenormalizer\n",
    "!apt install git-lfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'wget' from 'c:\\\\Users\\\\USER\\\\Lib\\\\site-packages\\\\wget.py'>\n"
     ]
    }
   ],
   "source": [
    "import wget\n",
    "print(wget)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "execution_failed": "2024-12-24T18:16:24.452Z",
     "iopub.execute_input": "2024-12-23T13:23:48.250360Z",
     "iopub.status.busy": "2024-12-23T13:23:48.250093Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' n'est pas reconnu en tant que commande interne\n",
      "ou externe, un programme ex�cutable ou un fichier de commandes.\n",
      "'unzip' n'est pas reconnu en tant que commande interne\n",
      "ou externe, un programme ex�cutable ou un fichier de commandes.\n",
      "'rm' n'est pas reconnu en tant que commande interne\n",
      "ou externe, un programme ex�cutable ou un fichier de commandes.\n",
      "'wget' n'est pas reconnu en tant que commande interne\n",
      "ou externe, un programme ex�cutable ou un fichier de commandes.\n",
      "'unzip' n'est pas reconnu en tant que commande interne\n",
      "ou externe, un programme ex�cutable ou un fichier de commandes.\n",
      "'rm' n'est pas reconnu en tant que commande interne\n",
      "ou externe, un programme ex�cutable ou un fichier de commandes.\n"
     ]
    }
   ],
   "source": [
    "# Download the first dataset\n",
    "!wget https://prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com/74p9d5frg3-1.zip -O /kaggle/working/dataset.zip\n",
    "!unzip /kaggle/working/dataset.zip -d /kaggle/working/YembaEGRA\n",
    "!rm /kaggle/working/dataset.zip\n",
    "\n",
    "# Download the second dataset\n",
    "!wget https://prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com/cx268tmrwn-3.zip -O /kaggle/working/dataset.zip\n",
    "!unzip /kaggle/working/dataset.zip -d /kaggle/working/\n",
    "!rm /kaggle/working/dataset.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T13:35:29.980623Z",
     "iopub.status.busy": "2024-12-23T13:35:29.980331Z",
     "iopub.status.idle": "2024-12-23T13:35:32.740428Z",
     "shell.execute_reply": "2024-12-23T13:35:32.739759Z",
     "shell.execute_reply.started": "2024-12-23T13:35:29.980602Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/working/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/metadata/isolated_words_dictionary.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m isolated_words_dictionary_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/working/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/metadata/isolated_words_dictionary.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m word_corpus_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/working/YembaEGRA/YembaEGRA/YembaEGRA/metadata/words_corpus .csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 7\u001b[0m isolated_words_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43misolated_words_dictionary_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m word_corpus_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(word_corpus_path)\n\u001b[0;32m     10\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYemba\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\USER\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    494\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 495\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\USER\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1550\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   1548\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1550\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m   1552\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1554\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1555\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1557\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\USER\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1402\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1400\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1404\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m   1405\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   1406\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\USER\\Lib\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/working/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/metadata/isolated_words_dictionary.xlsx'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "isolated_words_dictionary_path = \"/kaggle/working/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/metadata/isolated_words_dictionary.xlsx\"\n",
    "word_corpus_path = \"/kaggle/working/YembaEGRA/YembaEGRA/YembaEGRA/metadata/words_corpus .csv\"\n",
    "\n",
    "isolated_words_df = pd.read_excel(isolated_words_dictionary_path)\n",
    "word_corpus_df = pd.read_csv(word_corpus_path)\n",
    "\n",
    "df = pd.DataFrame(columns=[\"Yemba\", \"path\"])\n",
    "new_rows = []\n",
    "\n",
    "yemba_tones_base = \"/kaggle/working/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios\"\n",
    "yemba_egra_tones_base = \"/kaggle/working/YembaEGRA/YembaEGRA/YembaEGRA/audio\"\n",
    "\n",
    "speaker_length = 11\n",
    "groups_length = 149\n",
    "\n",
    "# Build rows from YembaTones\n",
    "for i in range(1, speaker_length + 1):\n",
    "    s_path = os.path.join(yemba_tones_base, f\"speaker_{i}\")\n",
    "    for j in range(1, groups_length + 1):\n",
    "        wav_count = 0\n",
    "        g_path = os.path.join(s_path, f\"group_{j}\")\n",
    "        if not os.path.exists(g_path):\n",
    "            continue\n",
    "        # Filter once outside the loop\n",
    "        filtered_df = isolated_words_df.loc[isolated_words_df['GroupeId'] == j]\n",
    "        max_len = len(filtered_df)\n",
    "        \n",
    "        for root, dirs, files in os.walk(g_path):\n",
    "            for file in files:\n",
    "                if file.endswith(\".wav\"):\n",
    "                    if wav_count < max_len:\n",
    "                        row_index = filtered_df.index[wav_count]\n",
    "                        save_path = os.path.join(root, file)\n",
    "                        new_rows.append({\n",
    "                            \"Yemba\": filtered_df[\"Yemba\"].iloc[wav_count],\n",
    "                            \"path\": save_path\n",
    "                        })\n",
    "                        wav_count += 1\n",
    "\n",
    "# Build rows from YembaEGRA\n",
    "ci_length = 8\n",
    "word_length = 60\n",
    "\n",
    "for i in range(1, ci_length + 1):\n",
    "    s_path = os.path.join(yemba_egra_tones_base, f\"CI{i}\")\n",
    "    for j in range(1, word_length + 1):\n",
    "        g_path  = os.path.join(s_path, f\"W{j}\")\n",
    "        if not os.path.exists(g_path):\n",
    "            continue\n",
    "        for root, dirs, files in os.walk(g_path):\n",
    "            for file in files:\n",
    "                if file.endswith(\".wav\"):\n",
    "                    save_path = os.path.join(root, file)\n",
    "                    filtered = word_corpus_df.loc[word_corpus_df['id_word'] == j]\n",
    "                    if len(filtered) > 0:\n",
    "                        yemba_value = filtered[\"Yemba\"].iloc[0]\n",
    "                        new_rows.append({\n",
    "                            \"Yemba\": yemba_value,\n",
    "                            \"path\": save_path\n",
    "                        })\n",
    "\n",
    "df = pd.concat([df, pd.DataFrame(new_rows)], ignore_index=True)\n",
    "\n",
    "# Shuffle and split\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "execution_failed": "2024-12-24T18:16:24.454Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'training_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DatasetDict, Audio\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 1) Read your CSV files\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m train_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_data.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m test_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtesting_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# 2) Ensure required columns exist\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\USER\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\USER\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'training_data.csv'"
     ]
    }
   ],
   "source": [
    "import soundfile as sf\n",
    "from datasets import Dataset, DatasetDict, Audio\n",
    "\n",
    "# 1) Read your CSV files\n",
    "train_df = pd.read_csv(\"training_data.csv\")\n",
    "test_df = pd.read_csv(\"testing_data.csv\")\n",
    "\n",
    "# 2) Ensure required columns exist\n",
    "required_cols = {\"path\", \"Yemba\"}\n",
    "if not required_cols.issubset(train_df.columns):\n",
    "    raise ValueError(\"Train CSV must contain 'path' and 'Yemba' columns.\")\n",
    "if not required_cols.issubset(test_df.columns):\n",
    "    raise ValueError(\"Test CSV must contain 'path' and 'Yemba' columns.\")\n",
    "\n",
    "# 3) Convert DataFrames to Hugging Face Datasets\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# 4) Verify audio paths and store them in the 'audio' column\n",
    "def verify_and_process_audio_column(batch):\n",
    "    audio_path = batch[\"path\"]\n",
    "\n",
    "    if not os.path.isfile(audio_path):\n",
    "        print(f\"File not found: {audio_path}. Skipping.\")\n",
    "        batch[\"audio\"] = None\n",
    "        return batch\n",
    "\n",
    "    try:\n",
    "        # Just to verify readability\n",
    "        _data, _sr = sf.read(audio_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Invalid audio file: {audio_path} ({e}). Skipping.\")\n",
    "        batch[\"audio\"] = None\n",
    "        return batch\n",
    "\n",
    "    batch[\"audio\"] = {\"path\": audio_path}\n",
    "    return batch\n",
    "\n",
    "train_dataset = train_dataset.map(verify_and_process_audio_column)\n",
    "test_dataset = test_dataset.map(verify_and_process_audio_column)\n",
    "\n",
    "def filter_invalid(batch):\n",
    "    return batch[\"audio\"] is not None\n",
    "\n",
    "train_dataset = train_dataset.filter(filter_invalid)\n",
    "test_dataset = test_dataset.filter(filter_invalid)\n",
    "\n",
    "# 5) Cast the valid 'audio' column to the Audio feature\n",
    "train_dataset = train_dataset.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "test_dataset = test_dataset.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "\n",
    "# Remove original 'path' if you no longer need it:\n",
    "train_dataset = train_dataset.remove_columns([\"path\"])\n",
    "test_dataset = test_dataset.remove_columns([\"path\"])\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"test\": test_dataset\n",
    "})\n",
    "\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T13:36:17.076894Z",
     "iopub.status.busy": "2024-12-23T13:36:17.076566Z",
     "iopub.status.idle": "2024-12-23T13:36:17.125825Z",
     "shell.execute_reply": "2024-12-23T13:36:17.125074Z",
     "shell.execute_reply.started": "2024-12-23T13:36:17.076865Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew_data_path_file.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"new_data_path_file.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T13:37:23.139063Z",
     "iopub.status.busy": "2024-12-23T13:37:23.138532Z",
     "iopub.status.idle": "2024-12-23T13:37:23.695683Z",
     "shell.execute_reply": "2024-12-23T13:37:23.694956Z",
     "shell.execute_reply.started": "2024-12-23T13:37:23.139026Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10282, 1143)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =df.sample(frac=1).reset_index(drop=True)\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data,test_data = train_test_split(df,test_size=0.1,shuffle=True)\n",
    "\n",
    "train_data.to_csv(\"training_data.csv\",index=False)\n",
    "test_data.to_csv(\"testing_data.csv\",index=False)\n",
    "\n",
    "len(train_data),len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T13:37:38.949864Z",
     "iopub.status.busy": "2024-12-23T13:37:38.949561Z",
     "iopub.status.idle": "2024-12-23T13:37:38.986335Z",
     "shell.execute_reply": "2024-12-23T13:37:38.985642Z",
     "shell.execute_reply.started": "2024-12-23T13:37:38.949842Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 10282  Test size: 1143\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = \\\n",
    "    pd.read_csv(\"training_data.csv\"), pd.read_csv(\"testing_data.csv\") \\\n",
    "    if os.path.isfile(\"training_data.csv\") and os.path.isfile(\"testing_data.csv\") \\\n",
    "    else (None, None)\n",
    "\n",
    "if train_data is None or test_data is None:\n",
    "    # If they don't exist, do train_test_split\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_data, test_data = train_test_split(df, test_size=0.1, shuffle=True)\n",
    "    train_data.to_csv(\"training_data.csv\", index=False)\n",
    "    test_data.to_csv(\"testing_data.csv\", index=False)\n",
    "\n",
    "print(\"Train size:\", len(train_data), \" Test size:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T13:38:57.048516Z",
     "iopub.status.busy": "2024-12-23T13:38:57.048176Z",
     "iopub.status.idle": "2024-12-23T13:39:05.233951Z",
     "shell.execute_reply": "2024-12-23T13:39:05.233107Z",
     "shell.execute_reply.started": "2024-12-23T13:38:57.048485Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03c85ccc86cd4b86b526b21fa34cf1cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10282 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid audio file: /kaggle/working/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_9/group_81/spkr_9_group_81_statement_1.wav (Error opening '/kaggle/working/YembaTones An Annotated Dataset for Tonal and Syllabic Analysis of the Yemba Language/Yemba_Dataset/audios/speaker_9/group_81/spkr_9_group_81_statement_1.wav': Format not recognised.). Skipping.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a8fd73c81554612878076de489c75d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1143 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b3d253f2773404b86dceab4157e01bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/10282 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab0292b827fc45d3ac1c960fc884da09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1143 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Yemba', 'audio'],\n",
      "        num_rows: 10281\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['Yemba', 'audio'],\n",
      "        num_rows: 1143\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "from datasets import Dataset, DatasetDict, Audio\n",
    "\n",
    "# 1) Read your CSV files\n",
    "train_df = pd.read_csv(\"training_data.csv\")\n",
    "test_df = pd.read_csv(\"testing_data.csv\")\n",
    "\n",
    "# 2) Ensure required columns exist\n",
    "required_cols = {\"path\", \"Yemba\"}\n",
    "if not required_cols.issubset(train_df.columns):\n",
    "    raise ValueError(\"Train CSV must contain 'path' and 'Yemba' columns.\")\n",
    "if not required_cols.issubset(test_df.columns):\n",
    "    raise ValueError(\"Test CSV must contain 'path' and 'Yemba' columns.\")\n",
    "\n",
    "# 3) Convert DataFrames to Hugging Face Datasets\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# 4) Verify audio paths and store them in the 'audio' column\n",
    "def verify_and_process_audio_column(batch):\n",
    "    audio_path = batch[\"path\"]\n",
    "\n",
    "    # Check if file exists\n",
    "    if not os.path.isfile(audio_path):\n",
    "        # Mark audio as None if missing\n",
    "        print(f\"File not found: {audio_path}. Skipping.\")\n",
    "        batch[\"audio\"] = None\n",
    "        return batch\n",
    "\n",
    "    # Attempt reading with soundfile just to confirm it's valid\n",
    "    try:\n",
    "        # We won't keep data in memory here; just verifying readability\n",
    "        _data, _sr = sf.read(audio_path)\n",
    "    except Exception as e:\n",
    "        # Mark audio as None if it's corrupted or unsupported\n",
    "        print(f\"Invalid audio file: {audio_path} ({e}). Skipping.\")\n",
    "        batch[\"audio\"] = None\n",
    "        return batch\n",
    "\n",
    "    # If valid, store path in 'audio'\n",
    "    batch[\"audio\"] = {\"path\": audio_path}\n",
    "    return batch\n",
    "\n",
    "train_dataset = train_dataset.map(verify_and_process_audio_column)\n",
    "test_dataset = test_dataset.map(verify_and_process_audio_column)\n",
    "\n",
    "# 5) Optionally filter out rows with invalid audio\n",
    "def filter_invalid(batch):\n",
    "    return batch[\"audio\"] is not None\n",
    "\n",
    "train_dataset = train_dataset.filter(filter_invalid)\n",
    "test_dataset = test_dataset.filter(filter_invalid)\n",
    "\n",
    "# 6) Cast the valid 'audio' column to the Audio feature\n",
    "train_dataset = train_dataset.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "test_dataset = test_dataset.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "\n",
    "# 7) Remove the original 'path' column\n",
    "train_dataset = train_dataset.remove_columns([\"path\"])\n",
    "test_dataset = test_dataset.remove_columns([\"path\"])\n",
    "\n",
    "# 8) Combine into a DatasetDict\n",
    "dataset = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"test\": test_dataset\n",
    "})\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T13:39:12.682143Z",
     "iopub.status.busy": "2024-12-23T13:39:12.681788Z",
     "iopub.status.idle": "2024-12-23T13:39:15.897646Z",
     "shell.execute_reply": "2024-12-23T13:39:15.896434Z",
     "shell.execute_reply.started": "2024-12-23T13:39:12.682091Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bnunicodenormalizer in /usr/local/lib/python3.10/dist-packages (0.1.7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72307422cd91405899825aaf102e848c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10281 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, NoneType found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ae34239e48fe>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalize_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/dataset_dict.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc)\u001b[0m\n\u001b[1;32m    884\u001b[0m             \u001b[0mcache_file_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m         return DatasetDict(\n\u001b[0;32m--> 886\u001b[0;31m             {\n\u001b[0m\u001b[1;32m    887\u001b[0m                 k: dataset.map(\n\u001b[1;32m    888\u001b[0m                     \u001b[0mfunction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/dataset_dict.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    885\u001b[0m         return DatasetDict(\n\u001b[1;32m    886\u001b[0m             {\n\u001b[0;32m--> 887\u001b[0;31m                 k: dataset.map(\n\u001b[0m\u001b[1;32m    888\u001b[0m                     \u001b[0mfunction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m                     \u001b[0mwith_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwith_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    558\u001b[0m         }\n\u001b[1;32m    559\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;31m# re-apply format to the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3071\u001b[0m                     \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"Map\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3072\u001b[0m                 ) as pbar:\n\u001b[0;32m-> 3073\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdataset_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3074\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m                             \u001b[0mshards_done\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3444\u001b[0m                     \u001b[0m_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3445\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshard_iterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3446\u001b[0;31m                         \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_function_on_filtered_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3447\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mupdate_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3448\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mapply_function_on_filtered_inputs\u001b[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   3336\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwith_rank\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3337\u001b[0m                 \u001b[0madditional_args\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3338\u001b[0;31m             \u001b[0mprocessed_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0madditional_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3339\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLazyDict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3340\u001b[0m                 processed_inputs = {\n",
      "\u001b[0;32m<ipython-input-13-ae34239e48fe>\u001b[0m in \u001b[0;36mnormalize_text\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnorm_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"normalized\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnorm_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mnorm_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"normalized\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Yemba\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: sequence item 0: expected str instance, NoneType found"
     ]
    }
   ],
   "source": [
    "!pip install bnunicodenormalizer\n",
    "from bnunicodenormalizer import Normalizer\n",
    "\n",
    "bnorm = Normalizer()\n",
    "\n",
    "def normalize_text(batch):\n",
    "    words = batch[\"Yemba\"].split()\n",
    "    norm_words = []\n",
    "    for w in words:\n",
    "        norm_dict = bnorm(w)  # returns {\"original\": ..., \"normalized\": ...}\n",
    "        if norm_dict and \"normalized\" in norm_dict:\n",
    "            norm_words.append(norm_dict[\"normalized\"])\n",
    "    batch[\"Yemba\"] = \" \".join(norm_words)\n",
    "    return batch\n",
    "\n",
    "dataset = dataset.map(normalize_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T13:37:48.603064Z",
     "iopub.status.busy": "2024-12-23T13:37:48.602779Z",
     "iopub.status.idle": "2024-12-23T13:37:48.644753Z",
     "shell.execute_reply": "2024-12-23T13:37:48.644090Z",
     "shell.execute_reply.started": "2024-12-23T13:37:48.603044Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 47\n",
      "Example chars: ['[UNK]', '[PAD]', ' ', \"'\", '-', 'A', 'E', 'K', 'L', 'M', 'N', 'S', 'T', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 's', 't', 'u', 'v', 'w', 'y', 'z', 'Ŋ', 'ŋ', 'ǝ', 'ɔ', 'ɛ', 'ʉ', 'ʼ', '̀', '́', '̄', '’']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# We'll reuse the CSV we built or dataset to collect unique characters\n",
    "# However, here you use the 'new_data_path_file.csv' from your code:\n",
    "csv_path = \"new_data_path_file.csv\"\n",
    "\n",
    "data_char = pd.read_csv(csv_path)\n",
    "\n",
    "if 'Yemba' not in data_char.columns:\n",
    "    raise ValueError(\"Ensure the CSV file has a 'Yemba' column for building vocab.\")\n",
    "\n",
    "words = data_char['Yemba'].dropna().unique()\n",
    "\n",
    "char_vocab = set(\"\".join(words))\n",
    "char_vocab = sorted(list(char_vocab))\n",
    "\n",
    "special_tokens = [\"[UNK]\", \"[PAD]\"]\n",
    "char_vocab = special_tokens + char_vocab\n",
    "\n",
    "char_to_index = {char: idx for idx, char in enumerate(char_vocab)}\n",
    "\n",
    "vocab_file = \"yemba_vocab.json\"\n",
    "with open(vocab_file, \"w\") as f:\n",
    "    json.dump(char_to_index, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"Vocabulary size:\", len(char_vocab))\n",
    "print(\"Example chars:\", char_vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T13:39:18.377196Z",
     "iopub.status.busy": "2024-12-23T13:39:18.376885Z",
     "iopub.status.idle": "2024-12-23T13:39:36.088204Z",
     "shell.execute_reply": "2024-12-23T13:39:36.086793Z",
     "shell.execute_reply.started": "2024-12-23T13:39:18.377171Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Git LFS initialized.\n",
      "Cloning into '/kaggle/working/wav2vec2-large-xlsr-53'...\n",
      "remote: Enumerating objects: 36, done.\u001b[K\n",
      "remote: Total 36 (delta 0), reused 0 (delta 0), pack-reused 36 (from 1)\u001b[K\n",
      "Unpacking objects: 100% (36/36), 5.35 KiB | 608.00 KiB/s, done.\n",
      "Filtering content: 100% (2/2), 2.36 GiB | 143.46 MiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "# Clone the repository\n",
    "!git lfs install\n",
    "!git clone https://huggingface.co/facebook/wav2vec2-large-xlsr-53 /kaggle/working/wav2vec2-large-xlsr-53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T13:55:39.925457Z",
     "iopub.status.busy": "2024-12-23T13:55:39.925095Z",
     "iopub.status.idle": "2024-12-23T13:55:43.020587Z",
     "shell.execute_reply": "2024-12-23T13:55:43.019715Z",
     "shell.execute_reply.started": "2024-12-23T13:55:39.925432Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at /kaggle/working/wav2vec2-large-xlsr-53 and are newly initialized: ['lm_head.bias', 'lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at /kaggle/working/wav2vec2-large-xlsr-53 and are newly initialized: ['lm_head.bias', 'lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom processor and model successfully loaded!\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    Wav2Vec2Processor,\n",
    "    Wav2Vec2FeatureExtractor,\n",
    "    Wav2Vec2CTCTokenizer,\n",
    "    Wav2Vec2ForCTC,\n",
    "Wav2Vec2Config\n",
    ")\n",
    "\n",
    "with open(\"yemba_vocab.json\", \"r\") as f:\n",
    "    yemba_vocab = json.load(f)\n",
    "\n",
    "tokenizer = Wav2Vec2CTCTokenizer(\n",
    "    vocab_file=\"yemba_vocab.json\",\n",
    "    unk_token=\"[UNK]\",\n",
    "    pad_token=\"[PAD]\",\n",
    "    word_delimiter_token=\"|\"  # or another if you prefer\n",
    ")\n",
    "\n",
    "# Load pretrained feature extractor\n",
    "model_name = \"/kaggle/working/wav2vec2-large-xlsr-53\"\n",
    "\n",
    "# 1) Load the base config\n",
    "config = Wav2Vec2Config.from_pretrained(model_name)\n",
    "# 2) Override the vocab_size\n",
    "config.vocab_size = tokenizer.vocab_size  # e.g., 47 or whatever yours is\n",
    "\n",
    "# 3) Create model with new config\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\n",
    "    model_name,\n",
    "    config=config,                # use updated config\n",
    "    ignore_mismatched_sizes=True  # allows final linear layer to resize\n",
    ")\n",
    "processor.save_pretrained(\"./custom-ssa-processor\")\n",
    "\n",
    "# Load the Wav2Vec2 model\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model_name)\n",
    "print(\"Custom processor and model successfully loaded!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T13:55:50.014680Z",
     "iopub.status.busy": "2024-12-23T13:55:50.014350Z",
     "iopub.status.idle": "2024-12-23T13:55:50.019533Z",
     "shell.execute_reply": "2024-12-23T13:55:50.018617Z",
     "shell.execute_reply.started": "2024-12-23T13:55:50.014651Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def prepare_dataset(batch):\n",
    "    \"\"\"\n",
    "    Prepares audio and text for Wav2Vec2 training.\n",
    "    dataset must have 'audio' (dict with 'array', 'sampling_rate') and 'Yemba' (string).\n",
    "    \"\"\"\n",
    "    audio_array = batch[\"audio\"][\"array\"]\n",
    "    sampling_rate = batch[\"audio\"][\"sampling_rate\"]\n",
    "\n",
    "    # Process input audio\n",
    "    inputs = processor(audio_array, sampling_rate=sampling_rate)\n",
    "    batch[\"input_values\"] = inputs.input_values[0]\n",
    "    batch[\"input_length\"] = len(batch[\"input_values\"])\n",
    "\n",
    "    # Process labels\n",
    "    labels = processor(text=batch[\"Yemba\"]).input_ids\n",
    "    batch[\"labels\"] = labels\n",
    "\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T13:55:51.331531Z",
     "iopub.status.busy": "2024-12-23T13:55:51.331197Z",
     "iopub.status.idle": "2024-12-23T14:00:40.455815Z",
     "shell.execute_reply": "2024-12-23T14:00:40.455066Z",
     "shell.execute_reply.started": "2024-12-23T13:55:51.331496Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b15b7b5d076643e4a91fa5cd8f4360b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10281 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bf726f257824d7bbbe3bc9a13147994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1143 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56394d0e8fd24730a1eb1dcde5d1f5a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/10281 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "616f27f9a3504ec39fd66834f93f8d25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1143 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ce0e14bf9d74e319a56901ae5a7a47e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10281 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "383477d5810641bb8142a3170db94f27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1143 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "524a8f98a94c4873a730e50bd1fe7ebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/10281 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b46fa4c947124ab1af7b21a68d309fb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1143 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_values', 'input_length', 'labels'],\n",
      "    num_rows: 10281\n",
      "}) Dataset({\n",
      "    features: ['input_values', 'input_length', 'labels'],\n",
      "    num_rows: 1143\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "def trim_silence(batch):\n",
    "    \"\"\"\n",
    "    Example function that tries to remove leading/trailing zeros.\n",
    "    Use caution: make sure it doesn't create empty arrays.\n",
    "    \"\"\"\n",
    "    arr = batch[\"input_values\"]\n",
    "    if len(arr) == 0:\n",
    "        return batch\n",
    "\n",
    "    # naive threshold-based trimming\n",
    "    threshold = 30\n",
    "    _max = max(abs(x) for x in arr) if len(arr) > 0 else 0\n",
    "    left_idx = 0\n",
    "    right_idx = len(arr) - 1\n",
    "\n",
    "    # find left cut\n",
    "    while left_idx < len(arr):\n",
    "        if abs(arr[left_idx]) * threshold > _max:\n",
    "            break\n",
    "        left_idx += 1\n",
    "\n",
    "    # find right cut\n",
    "    while right_idx >= 0:\n",
    "        if abs(arr[right_idx]) * threshold > _max:\n",
    "            break\n",
    "        right_idx -= 1\n",
    "\n",
    "    trimmed = arr[left_idx:right_idx+1]\n",
    "    batch[\"input_values\"] = trimmed\n",
    "    batch[\"input_length\"] = len(trimmed)\n",
    "    return batch\n",
    "\n",
    "# 1) Map prepare_dataset to create input_values & labels\n",
    "dataset_train = dataset[\"train\"].map(prepare_dataset, remove_columns=dataset[\"train\"].column_names)\n",
    "dataset_validation = dataset[\"test\"].map(prepare_dataset, remove_columns=dataset[\"test\"].column_names)\n",
    "\n",
    "# 2) Filter out empty labels\n",
    "def filter_empty_labels(batch):\n",
    "    return len(batch[\"labels\"]) > 0\n",
    "\n",
    "dataset_train = dataset_train.filter(filter_empty_labels)\n",
    "dataset_validation = dataset_validation.filter(filter_empty_labels)\n",
    "\n",
    "# 3) (Optional) Trim silence\n",
    "dataset_train = dataset_train.map(trim_silence)\n",
    "dataset_validation = dataset_validation.map(trim_silence)\n",
    "\n",
    "# 4) Filter out any zero-length audio after trimming\n",
    "def filter_zero_audio(batch):\n",
    "    return batch[\"input_length\"] > 0\n",
    "\n",
    "dataset_train = dataset_train.filter(filter_zero_audio)\n",
    "dataset_validation = dataset_validation.filter(filter_zero_audio)\n",
    "\n",
    "print(dataset_train, dataset_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T14:00:40.457136Z",
     "iopub.status.busy": "2024-12-23T14:00:40.456845Z",
     "iopub.status.idle": "2024-12-23T14:00:40.463640Z",
     "shell.execute_reply": "2024-12-23T14:00:40.462816Z",
     "shell.execute_reply.started": "2024-12-23T14:00:40.457093Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Union\n",
    "from transformers import Wav2Vec2Processor\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "    processor: Wav2Vec2Processor\n",
    "    padding: Union[bool, str] = True\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        input_features = [{\"input_values\": f[\"input_values\"]} for f in features]\n",
    "        label_features = [{\"input_ids\": f[\"labels\"]} for f in features]\n",
    "\n",
    "        batch = self.processor.pad(\n",
    "            input_features,\n",
    "            padding=self.padding,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        with self.processor.as_target_processor():\n",
    "            labels_batch = self.processor.pad(\n",
    "                label_features,\n",
    "                padding=self.padding,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "        batch[\"labels\"] = labels\n",
    "        return batch\n",
    "\n",
    "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T14:00:40.465188Z",
     "iopub.status.busy": "2024-12-23T14:00:40.464946Z",
     "iopub.status.idle": "2024-12-23T14:00:40.728544Z",
     "shell.execute_reply": "2024-12-23T14:00:40.727799Z",
     "shell.execute_reply.started": "2024-12-23T14:00:40.465167Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature encoder frozen.\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "wer_metric = evaluate.load(\"wer\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    pred_logits = pred.predictions\n",
    "    pred_ids = np.argmax(pred_logits, axis=-1)\n",
    "\n",
    "    # Replace -100 in labels with pad_token_id so we can decode\n",
    "    labels = pred.label_ids\n",
    "    labels[labels == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = processor.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
    "    return {\"wer\": wer}\n",
    "\n",
    "# Optionally freeze the feature encoder\n",
    "model.freeze_feature_encoder()\n",
    "print(\"Feature encoder frozen.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T13:50:04.687194Z",
     "iopub.status.busy": "2024-12-23T13:50:04.686816Z",
     "iopub.status.idle": "2024-12-23T13:50:04.704341Z",
     "shell.execute_reply": "2024-12-23T13:50:04.703321Z",
     "shell.execute_reply.started": "2024-12-23T13:50:04.687164Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2833404d7cb48c0a2005572dfc8ce96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T13:50:12.807147Z",
     "iopub.status.busy": "2024-12-23T13:50:12.806804Z",
     "iopub.status.idle": "2024-12-23T13:50:13.183933Z",
     "shell.execute_reply": "2024-12-23T13:50:13.183202Z",
     "shell.execute_reply.started": "2024-12-23T13:50:12.807094Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RepoUrl('https://huggingface.co/Ngoune/my-yemba-model_1', endpoint='https://huggingface.co', repo_type='model', repo_id='Ngoune/my-yemba-model_1')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import create_repo\n",
    "\n",
    "repo_name = \"my-yemba-model_1\"  # choose your unique name\n",
    "create_repo(repo_id=repo_name, private=False)  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T14:03:07.721719Z",
     "iopub.status.busy": "2024-12-23T14:03:07.721295Z",
     "iopub.status.idle": "2024-12-23T14:03:10.345541Z",
     "shell.execute_reply": "2024-12-23T14:03:10.344838Z",
     "shell.execute_reply.started": "2024-12-23T14:03:07.721677Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at /kaggle/working/wav2vec2-large-xlsr-53 and are newly initialized: ['lm_head.bias', 'lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = Wav2Vec2ForCTC.from_pretrained(\n",
    "    model_name,\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    ignore_mismatched_sizes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T14:03:12.659832Z",
     "iopub.status.busy": "2024-12-23T14:03:12.659542Z",
     "iopub.status.idle": "2024-12-23T14:03:12.665070Z",
     "shell.execute_reply": "2024-12-23T14:03:12.664188Z",
     "shell.execute_reply.started": "2024-12-23T14:03:12.659811Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.vocab_size == tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2024-12-24T18:16:24.454Z",
     "iopub.execute_input": "2024-12-23T14:50:07.257006Z",
     "iopub.status.busy": "2024-12-23T14:50:07.256722Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "<ipython-input-40-5d23fc0048ce>:30: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3105' max='9630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3105/9630 50:05 < 1:45:20, 1.03 it/s, Epoch 9.64/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2345.724000</td>\n",
       "      <td>433.756439</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1552.068300</td>\n",
       "      <td>316.668823</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "repo_name = \"my-yemba-model_1\"  # choose your unique name\n",
    "\n",
    "my_token = \"\"  # put your real token if pushing to the hub\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=repo_name,\n",
    "    report_to=\"none\",\n",
    "    # If pushing to hub, set these:\n",
    "    # hub_token=my_token,\n",
    "    # push_to_hub=True,\n",
    "    # hub_model_id=repo_name,\n",
    "\n",
    "    group_by_length=True,\n",
    "    per_device_train_batch_size=16,\n",
    "    gradient_accumulation_steps=2,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    num_train_epochs=30,\n",
    "    fp16=True,\n",
    "    gradient_checkpointing=True,\n",
    "    save_steps=9630,\n",
    "    eval_steps=1500,\n",
    "    logging_strategy=\"epoch\",\n",
    "    learning_rate=5e-7,\n",
    "    weight_decay=0.0000025,\n",
    "    warmup_steps=500,\n",
    "    save_total_limit=3,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=dataset_train,\n",
    "    eval_dataset=dataset_validation,\n",
    "    tokenizer=processor.feature_extractor,  # or just processor if it supports it\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer.push_to_hub()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
